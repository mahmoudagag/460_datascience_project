{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eee70489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\13473\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\13473\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\13473\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score \n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741d4c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc9467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "label         0\n",
      "text          0\n",
      "label_num     0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17752554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(a_string):\n",
    "    return a_string.lower()\n",
    "\n",
    "def remove_punctuation(a_string):    \n",
    "    a_string = re.sub(r'[^\\w\\s]','',a_string)\n",
    "    return a_string\n",
    "\n",
    "def remove_stopwords(a_string):\n",
    "    words = word_tokenize(a_string)\n",
    "    valid_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            valid_words.append(word)\n",
    "    a_string = ' '.join(valid_words)\n",
    "    return a_string\n",
    "\n",
    "def text_pipeline(input_string):\n",
    "    input_string = make_lower(input_string)\n",
    "    input_string = remove_punctuation(input_string)\n",
    "    input_string = remove_stopwords(input_string)    \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bdfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(text_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffddd79",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec22049",
   "metadata": {},
   "source": [
    "| Column      | Data Type   | Description | \n",
    "| :-----------: | :-----------: | :----------- |\n",
    "| Label       | String      | labeled as spam or ham representing if the text is spam or not |\n",
    "| Text        | String      | The emails |\n",
    "| Label_num   | Int         | A 0 or 1 representing spam or not respectively |\n",
    "| Text_clean  | String      | Cleaned version of the emails after passed through the text pipeline |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3920ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_clean'].values\n",
    "\n",
    "y = df['label_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b77ca8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1422beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "features = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ece649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4473225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.958454\n",
      "Precision Score: 0.890625\n",
      "Recall Score: 0.972696\n",
      "F1 Score: 0.929853\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "features_test = cv.transform(X_test)\n",
    "y_pred = model.predict(features_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "print('F1 Score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "927ea563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ae8edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "features = cv.fit_transform(X_train)\n",
    "features_test = cv.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d6292ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.974879\n",
      "Precision Score: 0.946488\n",
      "Recall Score: 0.965870\n",
      "F1 Score: 0.956081\n"
     ]
    }
   ],
   "source": [
    "## RandomForestClassifier\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "random_forest_model.fit(features, y_train)\n",
    "\n",
    "y_pred = random_forest_model.predict(features_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "print('F1 Score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8da3156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9a7ad",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315683c",
   "metadata": {},
   "source": [
    "The problem we are trying to address is spam email detection. We started by cleaning the emails. This included lower casing the email, removing punctuation and removing stop words. We then split our data into a testing and traning set. We then passed our training data into a count vectorizer which converts a collection of text documents to a matrix of token counts. Essentailly it counts the occurance of each word and assigns a token to that word. This allows use to pass words into a model which is what we need. We used 2 different models, Support Vector Classifier (SVC) and RandomForestClassifer. Lastly we measured the performace of both the models. Both models performed well, but the random forest classifer had slightly better performance with an accuracy score of 0.97, precision score of 0.94, recall Score of 0.96, and f1 score of 0.95.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c9fd2",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00ca8e",
   "metadata": {},
   "source": [
    "We knew from the beginning this was a classification problem and so we knew what types of models we needed, however the challenge was the nlp part. We needed to somehow input text to a model. This is where we discovered count vectorization, which allowed us to pass the text into the models. A current challenge we have is getting further insights of the model. The models are performing well, but they don't give us any insightful information on spam emails. We need to futher investigate what exactly we are doing and extrapolate any further information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd45d5",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a053291",
   "metadata": {},
   "source": [
    "For the future we want to test different hyperparameters to determine the best ones so that we can have the best model possible. We also want to further investigate how the model is making its desicion. We want to see if there are any specific words that most spam emails have or if there are other identifiers. Lastly we want to try to further our investigation. We want to ask ourselves better questions and gain further insights on the problem of spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf753ec1",
   "metadata": {},
   "source": [
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4265c",
   "metadata": {},
   "source": [
    "We contributed equalling. We were on a call, peer programming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
